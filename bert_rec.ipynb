{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mentee    1343\n",
       "mentor     550\n",
       "nan         35\n",
       "both         2\n",
       "Name: Relationship Role, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#maybe rid profiles where there are more than 5 NaNs, or rid profiles where there are len(profile) > 25\n",
    "#get rid of NaN relationship role \n",
    "\n",
    "df['Relationship Role'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /zfs/users/asda2/asda2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Profile</th>\n",
       "      <th>Relationship Role</th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1047538821</td>\n",
       "      <td>nan nan nan nan nan nan nan nan nan nan nan na...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047503435, 1.0, mentee), (1047538821, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1047497874</td>\n",
       "      <td>nan Alberni Secondary no idea,  nan I would li...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047513123, 1.0, mentee), (1047593968, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10698</td>\n",
       "      <td>, 0 nan nan nan pediatrician, veterinarian    ...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(10716, 1.0, mentee), (10702, 1.0, mentee), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1047549000</td>\n",
       "      <td>nan South Kamloops SS I would start a program ...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047585216, 1.0, mentee), (1047588253, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1047592264</td>\n",
       "      <td>nan nan Psychologist or a Forensic Psychiatris...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047503436, 1.0, mentee), (1047513309, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1047585221</td>\n",
       "      <td>nan Hope Secondary - Cattrell astronaut, engin...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047551394, 1.0, mentee), (1047584581, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1047583535</td>\n",
       "      <td>Douglas College, Bachelor of Arts in Applied C...</td>\n",
       "      <td>mentor</td>\n",
       "      <td>[(1047502278, 1.0, mentor), (1047513634, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1047627569</td>\n",
       "      <td>nan Charles Hays Secondary - Ling onboard engi...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047541619, 1.0, mentor), (1047549398, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1047501471</td>\n",
       "      <td>nan nan carpenter nan video games likes games ...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(15660, 1.0, mentee), (10241, 1.0, mentor), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>10988</td>\n",
       "      <td>, 12 nan nan nan Biophysics; Medicine nan nan ...</td>\n",
       "      <td>mentor</td>\n",
       "      <td>[(11588, 1.0, mentor), (10119, 1.0, mentor), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id                                            Profile  \\\n",
       "0    1047538821  nan nan nan nan nan nan nan nan nan nan nan na...   \n",
       "1    1047497874  nan Alberni Secondary no idea,  nan I would li...   \n",
       "2         10698  , 0 nan nan nan pediatrician, veterinarian    ...   \n",
       "3    1047549000  nan South Kamloops SS I would start a program ...   \n",
       "4    1047592264  nan nan Psychologist or a Forensic Psychiatris...   \n",
       "..          ...                                                ...   \n",
       "188  1047585221  nan Hope Secondary - Cattrell astronaut, engin...   \n",
       "189  1047583535  Douglas College, Bachelor of Arts in Applied C...   \n",
       "190  1047627569  nan Charles Hays Secondary - Ling onboard engi...   \n",
       "191  1047501471  nan nan carpenter nan video games likes games ...   \n",
       "192       10988  , 12 nan nan nan Biophysics; Medicine nan nan ...   \n",
       "\n",
       "    Relationship Role                                  Nearest Neighbors  \n",
       "0              mentee  [(1047503435, 1.0, mentee), (1047538821, 1.0, ...  \n",
       "1              mentee  [(1047513123, 1.0, mentee), (1047593968, 1.0, ...  \n",
       "2              mentee  [(10716, 1.0, mentee), (10702, 1.0, mentee), (...  \n",
       "3              mentee  [(1047585216, 1.0, mentee), (1047588253, 1.0, ...  \n",
       "4              mentee  [(1047503436, 1.0, mentee), (1047513309, 1.0, ...  \n",
       "..                ...                                                ...  \n",
       "188            mentee  [(1047551394, 1.0, mentee), (1047584581, 1.0, ...  \n",
       "189            mentor  [(1047502278, 1.0, mentor), (1047513634, 1.0, ...  \n",
       "190            mentee  [(1047541619, 1.0, mentor), (1047549398, 1.0, ...  \n",
       "191            mentee  [(15660, 1.0, mentee), (10241, 1.0, mentor), (...  \n",
       "192            mentor  [(11588, 1.0, mentor), (10119, 1.0, mentor), (...  \n",
       "\n",
       "[193 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "df = pd.read_csv(\"../../../clean_data/profiles.csv\", encoding='utf-8')\n",
    "df = df.astype(str).sample(frac=0.1, random_state=42)\n",
    "df['Profile'] = df.drop(columns=['Id', 'Created at', 'Relationship Role', 'Total Mentees', 'Number of Messages Sent', 'Resource Clicks', 'Courses Clicks']).agg(' '.join, axis=1)\n",
    "df['Tokens'] = df['Profile'].apply(word_tokenize)\n",
    "\n",
    "sentences = df['Tokens'].tolist()\n",
    "word2vec_model = Word2Vec(sentences, vector_size=200, window=5, min_count=1, workers=4)\n",
    "\n",
    "def average_word2vec(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "df['Vector'] = df['Tokens'].apply(lambda tokens: average_word2vec(tokens, word2vec_model))\n",
    "\n",
    "X = np.vstack(df['Vector'].values)\n",
    "\n",
    "# svd = TruncatedSVD(n_components=100)\n",
    "# X_reduced = svd.fit_transform(X)\n",
    "\n",
    "cos_sim_matrix = cosine_similarity(X)\n",
    "\n",
    "k = 5\n",
    "knn = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "knn.fit(X_reduced)\n",
    "\n",
    "distances, indices = knn.kneighbors(X_reduced)\n",
    "\n",
    "results = []\n",
    "for i, profile in enumerate(df['Profile']):\n",
    "    nearest_neighbors = [(df.iloc[indices[i][j]]['Id'], round(1 - distances[i][j], 2), df.iloc[indices[i][j]]['Relationship Role']) for j in range(1, k)]\n",
    "    result = {\n",
    "        'Id': df.iloc[i]['Id'],\n",
    "        'Profile': profile,\n",
    "        'Relationship Role': df.iloc[i]['Relationship Role'],\n",
    "        'Nearest Neighbors': nearest_neighbors\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /zfs/users/asda2/asda2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding variance:  0.0009967114\n",
      "Explained variance ratio:  0.999996\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Profile</th>\n",
       "      <th>Relationship Role</th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1047538821</td>\n",
       "      <td>nan nan nan nan nan nan nan nan nan nan nan na...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047538821, 1.0, mentee), (1047537906, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1047497874</td>\n",
       "      <td>nan Alberni Secondary no idea,  nan I would li...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047498727, 1.0, mentee), (1047516916, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10698</td>\n",
       "      <td>, 0 nan nan nan pediatrician, veterinarian    ...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(10716, 1.0, mentee), (1047584573, 1.0, mente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1047549000</td>\n",
       "      <td>nan South Kamloops SS I would start a program ...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047513634, 1.0, mentor), (1047594511, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1047592264</td>\n",
       "      <td>nan nan Psychologist or a Forensic Psychiatris...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047541038, 1.0, mentee), (1047514517, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1047585221</td>\n",
       "      <td>nan Hope Secondary - Cattrell astronaut, engin...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047496812, 1.0, mentee), (1047499338, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>1047583535</td>\n",
       "      <td>Douglas College, Bachelor of Arts in Applied C...</td>\n",
       "      <td>mentor</td>\n",
       "      <td>[(1047549055, 1.0, mentee), (1047549915, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>1047627569</td>\n",
       "      <td>nan Charles Hays Secondary - Ling onboard engi...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047514517, 1.0, mentor), (1047541032, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>1047501471</td>\n",
       "      <td>nan nan carpenter nan video games likes games ...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047499586, 1.0, mentee), (1047554084, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>10988</td>\n",
       "      <td>, 12 nan nan nan Biophysics; Medicine nan nan ...</td>\n",
       "      <td>mentor</td>\n",
       "      <td>[(11588, 1.0, mentor), (10330, 1.0, mentor), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id                                            Profile  \\\n",
       "0    1047538821  nan nan nan nan nan nan nan nan nan nan nan na...   \n",
       "1    1047497874  nan Alberni Secondary no idea,  nan I would li...   \n",
       "2         10698  , 0 nan nan nan pediatrician, veterinarian    ...   \n",
       "3    1047549000  nan South Kamloops SS I would start a program ...   \n",
       "4    1047592264  nan nan Psychologist or a Forensic Psychiatris...   \n",
       "..          ...                                                ...   \n",
       "188  1047585221  nan Hope Secondary - Cattrell astronaut, engin...   \n",
       "189  1047583535  Douglas College, Bachelor of Arts in Applied C...   \n",
       "190  1047627569  nan Charles Hays Secondary - Ling onboard engi...   \n",
       "191  1047501471  nan nan carpenter nan video games likes games ...   \n",
       "192       10988  , 12 nan nan nan Biophysics; Medicine nan nan ...   \n",
       "\n",
       "    Relationship Role                                  Nearest Neighbors  \n",
       "0              mentee  [(1047538821, 1.0, mentee), (1047537906, 1.0, ...  \n",
       "1              mentee  [(1047498727, 1.0, mentee), (1047516916, 1.0, ...  \n",
       "2              mentee  [(10716, 1.0, mentee), (1047584573, 1.0, mente...  \n",
       "3              mentee  [(1047513634, 1.0, mentor), (1047594511, 1.0, ...  \n",
       "4              mentee  [(1047541038, 1.0, mentee), (1047514517, 1.0, ...  \n",
       "..                ...                                                ...  \n",
       "188            mentee  [(1047496812, 1.0, mentee), (1047499338, 1.0, ...  \n",
       "189            mentor  [(1047549055, 1.0, mentee), (1047549915, 1.0, ...  \n",
       "190            mentee  [(1047514517, 1.0, mentor), (1047541032, 1.0, ...  \n",
       "191            mentee  [(1047499586, 1.0, mentee), (1047554084, 1.0, ...  \n",
       "192            mentor  [(11588, 1.0, mentor), (10330, 1.0, mentor), (...  \n",
       "\n",
       "[193 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "df = pd.read_csv(\"../../../clean_data/profiles.csv\", encoding='utf-8')\n",
    "df = df.astype(str).sample(frac=0.1, random_state=42)\n",
    "df['Profile'] = df.drop(columns=['Id', 'Created at', 'Relationship Role', 'Total Mentees', 'Number of Messages Sent', 'Resource Clicks', 'Courses Clicks']).agg(' '.join, axis=1)\n",
    "df['Tokens'] = df['Profile'].apply(word_tokenize)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "df['Tokens'] = df['Tokens'].apply(lambda tokens: [word for word in tokens if word.lower() not in stop_words])\n",
    "\n",
    "\n",
    "sentences = df['Tokens'].tolist()\n",
    "word2vec_model = Word2Vec(sentences, vector_size=200, window=5, min_count=1, workers=4)\n",
    "\n",
    "def average_word2vec(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "df['Vector'] = df['Tokens'].apply(lambda tokens: average_word2vec(tokens, word2vec_model))\n",
    "\n",
    "# embeddings quality\n",
    "print(\"Embedding variance: \", np.var(np.vstack(df['Vector'].values), axis=0).mean())\n",
    "\n",
    "X = np.vstack(df['Vector'].values)\n",
    "\n",
    "#   SVD\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "X_reduced = svd.fit_transform(X)\n",
    "print(\"Explained variance ratio: \", svd.explained_variance_ratio_.sum())\n",
    "\n",
    "# normalize \n",
    "X_normalized = normalize(X_reduced)\n",
    "\n",
    "cos_sim_matrix = cosine_similarity(X_normalized)\n",
    "\n",
    "k = 5\n",
    "knn = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "knn.fit(X_normalized)\n",
    "\n",
    "distances, indices = knn.kneighbors(X_normalized)\n",
    "\n",
    "results = []\n",
    "for i, profile in enumerate(df['Profile']):\n",
    "    nearest_neighbors = [(df.iloc[indices[i][j]]['Id'], round(1 - distances[i][j], 2), df.iloc[indices[i][j]]['Relationship Role']) for j in range(1, k)]\n",
    "    result = {\n",
    "        'Id': df.iloc[i]['Id'],\n",
    "        'Profile': profile,\n",
    "        'Relationship Role': df.iloc[i]['Relationship Role'],\n",
    "        'Nearest Neighbors': nearest_neighbors\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "134",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/ementoring/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/ementoring/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/ementoring/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 134",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, profile \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfile\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m---> 39\u001b[0m     nearest_neighbors \u001b[38;5;241m=\u001b[39m [(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m][indices[i][j]], \u001b[38;5;28mround\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m distances[i][j], \u001b[38;5;241m2\u001b[39m), df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelationship Role\u001b[39m\u001b[38;5;124m'\u001b[39m][indices[i][j]]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, k)]\n\u001b[1;32m     40\u001b[0m     result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m: df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m][i],\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfile\u001b[39m\u001b[38;5;124m'\u001b[39m: profile,\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelationship Role\u001b[39m\u001b[38;5;124m'\u001b[39m: df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelationship Role\u001b[39m\u001b[38;5;124m'\u001b[39m][i],\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNearest Neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m: nearest_neighbors\n\u001b[1;32m     45\u001b[0m     }\n\u001b[1;32m     46\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "Cell \u001b[0;32mIn[14], line 39\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, profile \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfile\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m---> 39\u001b[0m     nearest_neighbors \u001b[38;5;241m=\u001b[39m [(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m, \u001b[38;5;28mround\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m distances[i][j], \u001b[38;5;241m2\u001b[39m), df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelationship Role\u001b[39m\u001b[38;5;124m'\u001b[39m][indices[i][j]]) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, k)]\n\u001b[1;32m     40\u001b[0m     result \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m: df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m][i],\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfile\u001b[39m\u001b[38;5;124m'\u001b[39m: profile,\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelationship Role\u001b[39m\u001b[38;5;124m'\u001b[39m: df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelationship Role\u001b[39m\u001b[38;5;124m'\u001b[39m][i],\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNearest Neighbors\u001b[39m\u001b[38;5;124m'\u001b[39m: nearest_neighbors\n\u001b[1;32m     45\u001b[0m     }\n\u001b[1;32m     46\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend(result)\n",
      "File \u001b[0;32m~/miniconda3/envs/ementoring/lib/python3.8/site-packages/pandas/core/series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ementoring/lib/python3.8/site-packages/pandas/core/series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/miniconda3/envs/ementoring/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 134"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "df = pd.read_csv(\"../../../clean_data/profiles.csv\", encoding='utf-8')\n",
    "df = df.astype(str).sample(frac=0.1, random_state=42)\n",
    "df['Profile'] =  df.drop(columns=['Id', 'Created at', 'Relationship Role', 'Total Mentees', 'Number of Messages Sent', 'Resource Clicks', 'Courses Clicks']).agg(' '.join, axis=1)\n",
    "df['Tokens'] = df['Profile'].apply(word_tokenize)\n",
    "\n",
    "sentences = df['Tokens'].tolist()\n",
    "word2vec_model = Word2Vec(sentences, vector_size=200, window=5, min_count=1, workers=4)\n",
    "\n",
    "def average_word2vec(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "df['Vector'] = df['Tokens'].apply(lambda tokens: average_word2vec(tokens, word2vec_model))\n",
    "\n",
    "X = np.vstack(df['Vector'].values)\n",
    "\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "X_reduced = svd.fit_transform(X)\n",
    "\n",
    "cos_sim_matrix = cosine_similarity(X_reduced)\n",
    "\n",
    "k = 5\n",
    "knn = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "knn.fit(X_reduced)\n",
    "\n",
    "distances, indices = knn.kneighbors(X_reduced)\n",
    "\n",
    "results = []\n",
    "for i, profile in enumerate(df['Profile']):\n",
    "    nearest_neighbors = [(df['Id'][indices[i][j]], round(1 - distances[i][j], 2), df['Relationship Role'][indices[i][j]]) for j in range(1, k)]\n",
    "    result = {\n",
    "        'Id': df['Id'][i],\n",
    "        'Profile': profile,\n",
    "        'Relationship Role': df['Relationship Role'][i],\n",
    "        'Nearest Neighbors': nearest_neighbors\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "#print(results_df.to_string(index=False))\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m X_reduced2 \u001b[38;5;241m=\u001b[39m svd\u001b[38;5;241m.\u001b[39mfit_transform(X\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m      7\u001b[0m embedding_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_reduced2, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponent 1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponent 2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m embedding_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m     11\u001b[0m sns\u001b[38;5;241m.\u001b[39mscatterplot(data\u001b[38;5;241m=\u001b[39membedding_df, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponent 1\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponent 2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt \n",
    "import seaborn as sns \n",
    "\n",
    "svd = TruncatedSVD(n_components=2, random_state=69)  # must be 2 to vis\n",
    "X_reduced2 = svd.fit_transform(X.T)\n",
    "\n",
    "embedding_df = pd.DataFrame(X_reduced2, columns=['Component 1', 'Component 2'])\n",
    "embedding_df['word'] = X.columns\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(data=embedding_df, x='Component 1', y='Component 2')\n",
    "for i in range(embedding_df.shape[0]):\n",
    "    plt.text(embedding_df['Component 1'][i], embedding_df['Component 2'][i], embedding_df['word'][i])\n",
    "plt.title('Word Embeddings')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m BertModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Input df\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../../clean_data/profiles.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m     23\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProfile\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m  df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreated at\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRelationship Role\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Mentees\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNumber of Messages Sent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResource Clicks\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCourses Clicks\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39magg(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#using bert to tokenize and for word embeddings/vectors \n",
    "\n",
    "import random\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "\n",
    "#random seed for PyTorch (for GPU as well)\n",
    "torch.manual_seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "\ttorch.cuda.manual_seed_all(random_seed)\n",
    "\t\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Input df\n",
    "df = pd.read_csv(\"../../../clean_data/profiles.csv\", encoding='utf-8')\n",
    "df = df.astype(str)\n",
    "df['Profile'] =  df.drop(columns=['Id', 'Created at', 'Relationship Role', 'Total Mentees', 'Number of Messages Sent', 'Resource Clicks', 'Courses Clicks']).agg(' '.join, axis=1)\n",
    "\n",
    "# Tokenize and encode text using batch_encode_plus\n",
    "# The function returns a dictionary containing the token IDs and attention masks\n",
    "encoding = tokenizer.batch_encode_plus(\n",
    "\t\t\t\t\t # List of input texts\n",
    "\tpadding=True,\t\t\t # Pad to the maximum sequence length\n",
    "\ttruncation=True,\t\t # Truncate to the maximum sequence length if necessary\n",
    "\treturn_tensors='pt',\t # Return PyTorch tensors\n",
    "\tadd_special_tokens=True # Add special tokens CLS and SEP\n",
    ")\n",
    "\n",
    "input_ids = encoding['input_ids'] # Token IDs\n",
    "\n",
    "print(f\"Input ID: {input_ids}\")\n",
    "attention_mask = encoding['attention_mask'] # Attention mask\n",
    "\n",
    "print(f\"Attention mask: {attention_mask}\")\n",
    "\n",
    "# Generate embeddings using BERT model\n",
    "with torch.no_grad():\n",
    "\toutputs = model(input_ids, attention_mask=attention_mask)\n",
    "\tword_embeddings = outputs.last_hidden_state # This contains the embeddings\n",
    "\n",
    "# Output the shape of word embeddings\n",
    "print(f\"Shape of Word Embeddings: {word_embeddings.shape}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /zfs/users/asda2/asda2/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 269. GiB for an array with shape (268737, 268737) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m svd \u001b[38;5;241m=\u001b[39m TruncatedSVD(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     32\u001b[0m X_reduced \u001b[38;5;241m=\u001b[39m svd\u001b[38;5;241m.\u001b[39mfit_transform(X)\n\u001b[0;32m---> 34\u001b[0m cos_sim_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_reduced\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     37\u001b[0m knn \u001b[38;5;241m=\u001b[39m NearestNeighbors(n_neighbors\u001b[38;5;241m=\u001b[39mk, metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcosine\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ementoring/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:1401\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1399\u001b[0m     Y_normalized \u001b[38;5;241m=\u001b[39m normalize(Y, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 1401\u001b[0m K \u001b[38;5;241m=\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_normalized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_normalized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdense_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1403\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m K\n",
      "File \u001b[0;32m~/miniconda3/envs/ementoring/lib/python3.8/site-packages/sklearn/utils/extmath.py:189\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    187\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 189\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    192\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m ):\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 269. GiB for an array with shape (268737, 268737) and data type float32"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "df = pd.read_csv(\"../../../clean_data/profiles.csv\", encoding='utf-8')\n",
    "df = df.astype(str)\n",
    "df['Profile'] =  df.drop(columns=['Id', 'Created at', 'Relationship Role', 'Total Mentees', 'Number of Messages Sent', 'Resource Clicks', 'Courses Clicks']).agg(' '.join, axis=1)\n",
    "\n",
    "df['Tokens'] = df['Profile'].apply(word_tokenize)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def embed_bert(tokens, tokenizer, model):\n",
    "    inputs = tokenizer(tokens, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "\n",
    "df['Vector'] = df['Tokens'].apply(lambda tokens: embed_bert(tokens, tokenizer, model))\n",
    "\n",
    "X = np.vstack(df['Vector'].values)\n",
    "\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "X_reduced = svd.fit_transform(X)\n",
    "\n",
    "cos_sim_matrix = cosine_similarity(X_reduced)\n",
    "\n",
    "k = 5\n",
    "knn = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "knn.fit(X_reduced)\n",
    "\n",
    "distances, indices = knn.kneighbors(X_reduced)\n",
    "\n",
    "results = []\n",
    "for i, profile in enumerate(df['Profile']):\n",
    "    nearest_neighbors = [(df['Id'][indices[i][j]], round(1 - distances[i][j], 2), df['Relationship Role'][indices[i][j]]) for j in range(1, k)]\n",
    "    result = {\n",
    "        'Id': df['Id'][i],\n",
    "        'Profile': profile,\n",
    "        'Relationship Role': df['Relationship Role'][i],\n",
    "        'Nearest Neighbors': nearest_neighbors\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "df = pd.read_csv(\"../../../clean_data/profiles.csv\", encoding='utf-8')\n",
    "df = df.astype(str)\n",
    "df['Profile'] =  df.drop(columns=['Id', 'Created at', 'Relationship Role', 'Total Mentees', 'Number of Messages Sent', 'Resource Clicks', 'Courses Clicks']).agg(' '.join, axis=1)\n",
    "\n",
    "#df['Tokens'] = df['Profile'].apply(word_tokenize)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def embed_bert(tokens, tokenizer, model):\n",
    "    inputs = tokenizer(tokens, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "\n",
    "df['Vector'] = df['Tokens'].apply(lambda tokens: embed_bert(tokens, tokenizer, model))\n",
    "\n",
    "X = np.vstack(df['Vector'].values)\n",
    "\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "X_reduced = svd.fit_transform(X)\n",
    "\n",
    "cos_sim_matrix = cosine_similarity(X_reduced)\n",
    "\n",
    "k = 5\n",
    "knn = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "knn.fit(X_reduced)\n",
    "\n",
    "distances, indices = knn.kneighbors(X_reduced)\n",
    "\n",
    "results = []\n",
    "for i, profile in enumerate(df['Profile']):\n",
    "    nearest_neighbors = [(df['Id'][indices[i][j]], round(1 - distances[i][j], 2), df['Relationship Role'][indices[i][j]]) for j in range(1, k)]\n",
    "    result = {\n",
    "        'Id': df['Id'][i],\n",
    "        'Profile': profile,\n",
    "        'Relationship Role': df['Relationship Role'][i],\n",
    "        'Nearest Neighbors': nearest_neighbors\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ementoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
