{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mentee    1343\n",
       "mentor     550\n",
       "nan         35\n",
       "both         2\n",
       "Name: Relationship Role, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#maybe rid profiles where there are more than 5 NaNs, or rid profiles where there are len(profile) > 25\n",
    "#get rid of NaN relationship role \n",
    "\n",
    "df['Relationship Role'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Profile</th>\n",
       "      <th>Relationship Role</th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1047644182</td>\n",
       "      <td>I'm in my 3rd year in Cinema Studies at UBC. I...</td>\n",
       "      <td>mentor</td>\n",
       "      <td>[(1047550122, 1.0, mentor), (1047516499, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1047643231</td>\n",
       "      <td>nan South Kamloops SS Surgeon is my main goal ...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047564281, 1.0, mentee), (1047541071, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1047643230</td>\n",
       "      <td>nan South Kamloops SS dermatologist, zoologist...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047585080, 0.99, mentee), (1047549757, 0.99...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1047643228</td>\n",
       "      <td>I am third year Bachelor of Science, biology m...</td>\n",
       "      <td>mentor</td>\n",
       "      <td>[(1047549455, 1.0, mentor), (1047584290, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1047641732</td>\n",
       "      <td>nan South Kamloops SS Photographer, Teacher, P...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047627564, 1.0, mentee), (1047514517, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>9950</td>\n",
       "      <td>nan nan nan nan Marketing and Communications n...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(1047485501, 1.0, mentor), (1047514780, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>9941</td>\n",
       "      <td>nan nan nan nan nan Family, working out, readi...</td>\n",
       "      <td>mentor</td>\n",
       "      <td>[(15660, 0.99, mentee), (11057, 0.99, mentor),...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>9927</td>\n",
       "      <td>nan nan nan nan Rural Medicine nan nan nan nan...</td>\n",
       "      <td>mentor</td>\n",
       "      <td>[(10160, 1.0, mentor), (10162, 1.0, mentor), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>9923</td>\n",
       "      <td>nan nan nan nan Nursing nan nan nan nan , 1 , ...</td>\n",
       "      <td>mentee</td>\n",
       "      <td>[(10150, 1.0, mentor), (10143, 1.0, mentor), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>9664</td>\n",
       "      <td>, 2 nan nan nan Indigenous Education nan nan n...</td>\n",
       "      <td>mentor</td>\n",
       "      <td>[(12537, 1.0, mentor), (11109, 1.0, mentor), (...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1930 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id                                            Profile  \\\n",
       "0     1047644182  I'm in my 3rd year in Cinema Studies at UBC. I...   \n",
       "1     1047643231  nan South Kamloops SS Surgeon is my main goal ...   \n",
       "2     1047643230  nan South Kamloops SS dermatologist, zoologist...   \n",
       "3     1047643228  I am third year Bachelor of Science, biology m...   \n",
       "4     1047641732  nan South Kamloops SS Photographer, Teacher, P...   \n",
       "...          ...                                                ...   \n",
       "1925        9950  nan nan nan nan Marketing and Communications n...   \n",
       "1926        9941  nan nan nan nan nan Family, working out, readi...   \n",
       "1927        9927  nan nan nan nan Rural Medicine nan nan nan nan...   \n",
       "1928        9923  nan nan nan nan Nursing nan nan nan nan , 1 , ...   \n",
       "1929        9664  , 2 nan nan nan Indigenous Education nan nan n...   \n",
       "\n",
       "     Relationship Role                                  Nearest Neighbors  \n",
       "0               mentor  [(1047550122, 1.0, mentor), (1047516499, 1.0, ...  \n",
       "1               mentee  [(1047564281, 1.0, mentee), (1047541071, 1.0, ...  \n",
       "2               mentee  [(1047585080, 0.99, mentee), (1047549757, 0.99...  \n",
       "3               mentor  [(1047549455, 1.0, mentor), (1047584290, 1.0, ...  \n",
       "4               mentee  [(1047627564, 1.0, mentee), (1047514517, 1.0, ...  \n",
       "...                ...                                                ...  \n",
       "1925            mentee  [(1047485501, 1.0, mentor), (1047514780, 1.0, ...  \n",
       "1926            mentor  [(15660, 0.99, mentee), (11057, 0.99, mentor),...  \n",
       "1927            mentor  [(10160, 1.0, mentor), (10162, 1.0, mentor), (...  \n",
       "1928            mentee  [(10150, 1.0, mentor), (10143, 1.0, mentor), (...  \n",
       "1929            mentor  [(12537, 1.0, mentor), (11109, 1.0, mentor), (...  \n",
       "\n",
       "[1930 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "df = pd.read_csv(\"../../../clean_data/profiles.csv\", encoding='utf-8')\n",
    "df = df.astype(str)\n",
    "df['Profile'] =  df.drop(columns=['Id', 'Created at', 'Relationship Role', 'Total Mentees', 'Number of Messages Sent', 'Resource Clicks', 'Courses Clicks']).agg(' '.join, axis=1)\n",
    "df['Tokens'] = df['Profile'].apply(word_tokenize)\n",
    "\n",
    "sentences = df['Tokens'].tolist()\n",
    "word2vec_model = Word2Vec(sentences, vector_size=200, window=5, min_count=1, workers=4)\n",
    "\n",
    "def average_word2vec(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    return np.mean(vectors, axis=0) if vectors else np.zeros(model.vector_size)\n",
    "\n",
    "df['Vector'] = df['Tokens'].apply(lambda tokens: average_word2vec(tokens, word2vec_model))\n",
    "\n",
    "X = np.vstack(df['Vector'].values)\n",
    "\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "X_reduced = svd.fit_transform(X)\n",
    "\n",
    "cos_sim_matrix = cosine_similarity(X_reduced)\n",
    "\n",
    "k = 5\n",
    "knn = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "knn.fit(X_reduced)\n",
    "\n",
    "distances, indices = knn.kneighbors(X_reduced)\n",
    "\n",
    "results = []\n",
    "for i, profile in enumerate(df['Profile']):\n",
    "    nearest_neighbors = [(df['Id'][indices[i][j]], round(1 - distances[i][j], 2), df['Relationship Role'][indices[i][j]]) for j in range(1, k)]\n",
    "    result = {\n",
    "        'Id': df['Id'][i],\n",
    "        'Profile': profile,\n",
    "        'Relationship Role': df['Relationship Role'][i],\n",
    "        'Nearest Neighbors': nearest_neighbors\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "#print(results_df.to_string(index=False))\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m X_reduced2 \u001b[38;5;241m=\u001b[39m svd\u001b[38;5;241m.\u001b[39mfit_transform(X\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m      7\u001b[0m embedding_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_reduced2, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponent 1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponent 2\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 8\u001b[0m embedding_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m     11\u001b[0m sns\u001b[38;5;241m.\u001b[39mscatterplot(data\u001b[38;5;241m=\u001b[39membedding_df, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponent 1\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComponent 2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt \n",
    "import seaborn as sns \n",
    "\n",
    "svd = TruncatedSVD(n_components=2, random_state=69)  # must be 2 to vis\n",
    "X_reduced2 = svd.fit_transform(X.T)\n",
    "\n",
    "embedding_df = pd.DataFrame(X_reduced2, columns=['Component 1', 'Component 2'])\n",
    "embedding_df['word'] = X.columns\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.scatterplot(data=embedding_df, x='Component 1', y='Component 2')\n",
    "for i in range(embedding_df.shape[0]):\n",
    "    plt.text(embedding_df['Component 1'][i], embedding_df['Component 2'][i], embedding_df['word'][i])\n",
    "plt.title('Word Embeddings')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using bert to tokenize and for word embeddings/vectors \n",
    "\n",
    "import random\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "\n",
    "#random seed for PyTorch (for GPU as well)\n",
    "torch.manual_seed(random_seed)\n",
    "if torch.cuda.is_available():\n",
    "\ttorch.cuda.manual_seed_all(random_seed)\n",
    "\t\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Input df\n",
    "df = pd.read_csv(\"../../../clean_data/profiles.csv\", encoding='utf-8')\n",
    "df = df.astype(str)\n",
    "df['Profile'] =  df.drop(columns=['Id', 'Created at', 'Relationship Role', 'Total Mentees', 'Number of Messages Sent', 'Resource Clicks', 'Courses Clicks']).agg(' '.join, axis=1)\n",
    "\n",
    "# Tokenize and encode text using batch_encode_plus\n",
    "# The function returns a dictionary containing the token IDs and attention masks\n",
    "encoding = tokenizer.batch_encode_plus(\n",
    "\t\t\t\t\t # List of input texts\n",
    "\tpadding=True,\t\t\t # Pad to the maximum sequence length\n",
    "\ttruncation=True,\t\t # Truncate to the maximum sequence length if necessary\n",
    "\treturn_tensors='pt',\t # Return PyTorch tensors\n",
    "\tadd_special_tokens=True # Add special tokens CLS and SEP\n",
    ")\n",
    "\n",
    "input_ids = encoding['input_ids'] # Token IDs\n",
    "\n",
    "print(f\"Input ID: {input_ids}\")\n",
    "attention_mask = encoding['attention_mask'] # Attention mask\n",
    "\n",
    "print(f\"Attention mask: {attention_mask}\")\n",
    "\n",
    "# Generate embeddings using BERT model\n",
    "with torch.no_grad():\n",
    "\toutputs = model(input_ids, attention_mask=attention_mask)\n",
    "\tword_embeddings = outputs.last_hidden_state # This contains the embeddings\n",
    "\n",
    "# Output the shape of word embeddings\n",
    "print(f\"Shape of Word Embeddings: {word_embeddings.shape}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ementoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
