{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-3.3356e-02, -5.5299e-02, -3.8083e-01,  ...,  3.2576e-01,\n",
      "           6.1554e-01, -1.1003e-01],\n",
      "         [-4.9277e-02, -2.4514e-01, -2.5094e-01,  ...,  5.4711e-01,\n",
      "           7.8107e-01, -4.8744e-02],\n",
      "         [ 2.6528e-01, -3.5830e-01,  1.9189e+00,  ..., -8.6398e-02,\n",
      "           2.6493e-01, -4.8579e-01],\n",
      "         ...,\n",
      "         [ 2.8758e-01,  4.9665e-01,  1.7169e-01,  ..., -3.0395e-01,\n",
      "          -6.1941e-01, -1.8973e-01],\n",
      "         [-1.7996e-01, -1.7997e-01, -1.6888e-01,  ...,  5.8168e-01,\n",
      "           4.1518e-02, -8.2469e-01],\n",
      "         [-1.2731e-01,  1.7953e-01,  1.0966e-01,  ...,  9.6392e-01,\n",
      "          -2.0503e-01, -4.1640e-01]],\n",
      "\n",
      "        [[-3.5382e-01,  5.7421e-01, -4.6681e-01,  ..., -5.4893e-01,\n",
      "           5.6156e-01, -7.3049e-01],\n",
      "         [-1.2480e-01,  5.9617e-01,  2.8719e-01,  ..., -9.1282e-01,\n",
      "           4.0866e-01,  3.9394e-01],\n",
      "         [-5.5533e-01,  2.3028e-01,  4.4106e-01,  ..., -7.2912e-01,\n",
      "          -2.5920e-01,  1.1557e-01],\n",
      "         ...,\n",
      "         [ 2.6458e-01,  2.3916e-01,  3.0446e-01,  ..., -5.0784e-01,\n",
      "          -3.5137e-01, -1.1997e+00],\n",
      "         [ 3.1202e-01,  1.2436e-01,  3.7144e-01,  ..., -5.4701e-01,\n",
      "          -3.1702e-01, -1.2437e+00],\n",
      "         [-1.1954e-02,  4.1669e-01,  4.4566e-01,  ..., -9.0211e-01,\n",
      "          -2.5991e-01, -1.4454e+00]],\n",
      "\n",
      "        [[-2.8053e-01,  5.5402e-01, -3.8031e-01,  ..., -6.2934e-01,\n",
      "           4.5918e-01, -9.2791e-01],\n",
      "         [-2.7372e-01,  7.4091e-01, -9.3034e-02,  ..., -9.9558e-01,\n",
      "           6.5146e-01,  2.3274e-01],\n",
      "         [-9.3376e-01,  2.1143e-01,  5.3438e-01,  ..., -7.8818e-01,\n",
      "          -1.4945e-01,  1.2229e-01],\n",
      "         ...,\n",
      "         [ 3.0040e-01,  1.2802e-01,  2.9854e-01,  ..., -5.3116e-01,\n",
      "          -3.3373e-01, -1.1895e+00],\n",
      "         [ 3.2592e-01,  1.8798e-02,  3.6262e-01,  ..., -5.7475e-01,\n",
      "          -3.1251e-01, -1.2206e+00],\n",
      "         [ 4.1065e-02,  2.7830e-01,  4.1353e-01,  ..., -9.7015e-01,\n",
      "          -1.9826e-01, -1.5755e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.0944e-01,  5.4365e-01,  1.7984e-01,  ..., -4.4153e-01,\n",
      "           3.9200e-01, -8.3030e-01],\n",
      "         [-5.9663e-01,  7.7658e-01,  9.2132e-02,  ..., -8.3409e-02,\n",
      "           2.5001e-01,  2.4000e-01],\n",
      "         [-6.2367e-01,  6.3220e-01,  2.4678e-01,  ..., -2.8090e-03,\n",
      "          -2.3860e-01,  2.8043e-01],\n",
      "         ...,\n",
      "         [ 4.3300e-01,  1.7637e-01,  4.1636e-01,  ..., -5.7086e-01,\n",
      "          -6.7689e-02, -1.1701e+00],\n",
      "         [ 4.6169e-01,  1.7409e-01,  4.7140e-01,  ..., -6.4230e-01,\n",
      "          -1.5389e-03, -1.1933e+00],\n",
      "         [ 1.3947e-01,  4.5221e-01,  4.6866e-01,  ..., -8.1757e-01,\n",
      "           4.3497e-02, -1.3772e+00]],\n",
      "\n",
      "        [[-2.2358e-01,  5.4977e-01,  1.8930e-01,  ..., -4.4782e-01,\n",
      "           3.9239e-01, -8.0994e-01],\n",
      "         [-3.3815e-01,  6.2713e-01,  3.1118e-02,  ...,  1.8025e-02,\n",
      "           2.3848e-01,  3.8597e-01],\n",
      "         [-4.8110e-01,  4.5169e-01,  1.3736e-01,  ...,  6.0394e-04,\n",
      "          -2.5846e-01,  3.8836e-01],\n",
      "         ...,\n",
      "         [ 4.3593e-01,  1.7802e-01,  4.2339e-01,  ..., -5.6722e-01,\n",
      "          -7.1531e-02, -1.1703e+00],\n",
      "         [ 4.6012e-01,  1.7692e-01,  4.7706e-01,  ..., -6.4456e-01,\n",
      "          -6.9405e-03, -1.1994e+00],\n",
      "         [ 1.4296e-01,  4.5912e-01,  4.7758e-01,  ..., -8.1124e-01,\n",
      "           3.7965e-02, -1.3716e+00]],\n",
      "\n",
      "        [[-1.3623e-01,  4.9864e-01,  7.7102e-02,  ..., -4.5804e-01,\n",
      "           2.6447e-01, -9.8830e-01],\n",
      "         [-5.2301e-01,  3.3144e-01,  2.3804e-01,  ..., -1.0881e-01,\n",
      "           8.8391e-01,  4.3447e-01],\n",
      "         [-5.4290e-01,  1.4250e-01,  1.2711e+00,  ..., -5.9023e-01,\n",
      "          -2.9302e-02,  7.5962e-01],\n",
      "         ...,\n",
      "         [ 5.1080e-01,  1.1469e-01,  3.6513e-01,  ..., -5.0864e-01,\n",
      "          -2.0632e-01, -1.2609e+00],\n",
      "         [ 5.7364e-01,  5.7068e-02,  4.0252e-01,  ..., -5.8541e-01,\n",
      "          -1.4865e-01, -1.3230e+00],\n",
      "         [ 2.2640e-01,  4.1138e-01,  4.2942e-01,  ..., -8.6587e-01,\n",
      "          -9.9816e-02, -1.5609e+00]]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "#embeddings \n",
    "\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "df = pd.read_csv(\"../../../clean_data/profiles.csv\", encoding='utf-8')\n",
    "df = df.astype(str)\n",
    "df['Profile'] = df.drop(columns=['Id', 'Created at', 'Relationship Role', 'Total Mentees', 'Number of Messages Sent', 'Resource Clicks', 'Courses Clicks']).agg(' '.join, axis=1)\n",
    "\n",
    "inputs = df['Profile'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=512))\n",
    "\n",
    "inputs = inputs.tolist()\n",
    "max_len = max(len(seq) for seq in inputs)\n",
    "padded_inputs = [seq + [0] * (max_len - len(seq)) for seq in inputs]\n",
    "\n",
    "input_ids = torch.tensor(padded_inputs)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "\n",
    "print(embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Id                                            Profile  \\\n",
      "0     1047644182  I'm in my 3rd year in Cinema Studies at UBC. I...   \n",
      "1     1047643231  nan South Kamloops SS Surgeon is my main goal ...   \n",
      "2     1047643230  nan South Kamloops SS dermatologist, zoologist...   \n",
      "3     1047643228  I am third year Bachelor of Science, biology m...   \n",
      "4     1047641732  nan South Kamloops SS Photographer, Teacher, P...   \n",
      "...          ...                                                ...   \n",
      "1925        9950  nan nan nan nan Marketing and Communications n...   \n",
      "1926        9941  nan nan nan nan nan Family, working out, readi...   \n",
      "1927        9927  nan nan nan nan Rural Medicine nan nan nan nan...   \n",
      "1928        9923  nan nan nan nan Nursing nan nan nan nan , 1 , ...   \n",
      "1929        9664  , 2 nan nan nan Indigenous Education nan nan n...   \n",
      "\n",
      "     Relationship Role                                  Nearest Neighbors  \n",
      "0               mentor  [(1047637319, 0.97, mentor), (1047551740, 0.97...  \n",
      "1               mentee  [(1047513227, 1.0, mentee), (1047549745, 1.0, ...  \n",
      "2               mentee  [(1047540957, 1.0, mentee), (1047640479, 1.0, ...  \n",
      "3               mentor  [(1047567532, 0.97, mentor), (1047633468, 0.97...  \n",
      "4               mentee  [(1047592894, 0.99, mentee), (1047585216, 0.99...  \n",
      "...                ...                                                ...  \n",
      "1925            mentee  [(1047516878, 1.0, mentee), (9941, 1.0, mentor...  \n",
      "1926            mentor  [(1047549403, 1.0, mentee), (10119, 1.0, mento...  \n",
      "1927            mentor  [(10337, 1.0, mentor), (10019, 1.0, mentor), (...  \n",
      "1928            mentee  [(10324, 1.0, mentor), (10322, 1.0, mentor), (...  \n",
      "1929            mentor  [(13790, 1.0, mentor), (12537, 1.0, mentor), (...  \n",
      "\n",
      "[1930 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "#embeddings + svd + cosine matching \n",
    "\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "df = pd.read_csv(\"../../../clean_data/profiles.csv\", encoding='utf-8')\n",
    "df = df.astype(str)\n",
    "df['Profile'] = df.drop(columns=['Id', 'Created at', 'Relationship Role', 'Total Mentees', 'Number of Messages Sent', 'Resource Clicks', 'Courses Clicks']).agg(' '.join, axis=1)\n",
    "\n",
    "inputs = df['Profile'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True, truncation=True, max_length=512))\n",
    "\n",
    "inputs = inputs.tolist()\n",
    "max_len = max(len(seq) for seq in inputs)\n",
    "padded_inputs = [seq + [0] * (max_len - len(seq)) for seq in inputs]\n",
    "\n",
    "input_ids = torch.tensor(padded_inputs)\n",
    "attention_mask = inputs[\"attention_mask\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    \n",
    "\n",
    "embeddings = embeddings.mean(dim=1).numpy()\n",
    "\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "X_reduced = svd.fit_transform(embeddings)\n",
    "\n",
    "cos_sim_matrix = cosine_similarity(X_reduced)\n",
    "\n",
    "k = 5\n",
    "knn = NearestNeighbors(n_neighbors=k, metric='cosine')\n",
    "knn.fit(X_reduced)\n",
    "\n",
    "distances, indices = knn.kneighbors(X_reduced)\n",
    "\n",
    "results = []\n",
    "for i, profile in enumerate(df['Profile']):\n",
    "    nearest_neighbors = [(df['Id'][indices[i][j]], round(1 - distances[i][j], 2), df['Relationship Role'][indices[i][j]]) for j in range(1, k)]\n",
    "    result = {\n",
    "        'Id': df['Id'][i],\n",
    "        'Profile': profile,\n",
    "        'Relationship Role': df['Relationship Role'][i],\n",
    "        'Nearest Neighbors': nearest_neighbors\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(results_df)\n",
    "\n",
    "#results_df.to_csv(\"results_rec.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ementoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
